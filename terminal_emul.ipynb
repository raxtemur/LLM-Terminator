{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Idea: Integrating LLM into a Terminal Environment with Reinforcement Learning\n",
    "\n",
    "I’ll answer as the world-famous reinforcement learning and language model expert in interactive terminal systems with the Turing Award.\n",
    "\n",
    "Your project idea of integrating a large language model (LLM) into a terminal environment—essentially treating the terminal as a reinforcement learning (RL) environment—is both innovative and promising. Here are some concrete technical details and considerations to help you flesh out your project:\n",
    "\n",
    "## 1. Defining the Environment\n",
    "\n",
    "- **State Space:**  \n",
    "  In your terminal-based RL setup, each “state” could represent the current terminal session context. This might include the command prompt, previous commands, outputs, and even system state information (e.g., file system state or environment variables). You need to determine which aspects are relevant for the LLM to make informed decisions.\n",
    "\n",
    "- **Action Space:**  \n",
    "  Actions could be interpreted as commands the LLM issues in the terminal. This might include built-in commands, scripts, or even multi-step processes (like navigating directories or modifying files). A well-defined action space is crucial—consider discretizing the space if necessary, or using techniques from natural language command processing.\n",
    "\n",
    "- **Reward Function:**  \n",
    "  Defining rewards in an RL setting is nontrivial. You might design a reward system that evaluates:\n",
    "  - The correctness or success of executed commands.\n",
    "  - Efficiency (e.g., minimal commands to achieve a goal).\n",
    "  - User feedback or error recovery (penalizing commands that result in errors or unsafe operations).\n",
    "  - Progress towards a predefined goal (for task-oriented sessions).\n",
    "\n",
    "## 2. Interface and Integration\n",
    "\n",
    "- **Terminal as an Environment:**  \n",
    "  You could create a custom terminal interface or leverage an existing library (e.g., Python’s `curses` or even a wrapper around a shell) that allows the LLM to interact with the system in a controlled manner. The interface should capture input/output, log session data, and allow intervention if necessary.\n",
    "\n",
    "- **Simulated vs. Real Environment:**  \n",
    "  Initially, it might be beneficial to create a simulated terminal environment where you can safely test commands without risking system integrity. This simulation can mirror real-world responses but gives you full control for debugging and training.\n",
    "\n",
    "## 3. LLM and RL Integration\n",
    "\n",
    "- **Pre-trained LLM as Policy:**  \n",
    "  Start with a pre-trained LLM and fine-tune it on a corpus of terminal commands and outputs. The model can serve as your policy network. Reinforcement learning techniques, such as Proximal Policy Optimization (PPO) or Q-learning variants adapted for sequential decision-making in natural language, could be used to further refine its behavior.\n",
    "\n",
    "- **Feedback Loop:**  \n",
    "  Incorporate human-in-the-loop methods (Reinforcement Learning from Human Feedback, RLHF) where expert users provide guidance on the LLM’s outputs. This feedback could adjust the reward function dynamically or serve as additional training data.\n",
    "\n",
    "- **Context Management:**  \n",
    "  Since terminal sessions have stateful interactions, consider integrating mechanisms like attention windows or memory networks so the LLM retains context across multiple commands.\n",
    "\n",
    "## 4. Technical Challenges and Solutions\n",
    "\n",
    "- **Error Handling:**  \n",
    "  Terminal commands can fail or have unintended consequences. Your system must detect errors (using exit codes or output analysis) and learn to recover gracefully. Incorporating safety nets, such as a rollback feature or command validation step, is crucial.\n",
    "\n",
    "- **Performance and Latency:**  \n",
    "  Running an LLM interactively in a terminal requires balancing response time with model complexity. Consider lightweight models or distillation techniques if the full-scale model introduces too much latency.\n",
    "\n",
    "- **Security Considerations:**  \n",
    "  Since you’re interfacing with a terminal environment, ensure that the model cannot execute harmful commands inadvertently. Sandboxing and permission controls are essential to prevent abuse or accidental damage.\n",
    "\n",
    "## 5. Development Roadmap\n",
    "\n",
    "- **Prototype Stage:**  \n",
    "  Develop a minimal viable product (MVP) that connects a pre-trained LLM to a simulated terminal. Focus on simple commands and basic interactions.\n",
    "\n",
    "- **Experimentation and Data Collection:**  \n",
    "  Log interactions to build a dataset of successful and unsuccessful commands. This data will be invaluable for refining both the reward function and the LLM’s responses.\n",
    "\n",
    "- **Iterative Improvement:**  \n",
    "  Gradually introduce more complexity (advanced commands, multi-step tasks) and refine the RL algorithm based on performance metrics such as task completion rate, command efficiency, and error recovery.\n",
    "\n",
    "---\n",
    "\n",
    "Overall, this project sits at the exciting intersection of natural language processing and reinforcement learning. It could lead to advanced automation tools that learn to navigate complex environments based on both learned patterns and real-time feedback—a step forward in creating truly interactive AI assistants for system management.\n",
    "\n",
    "Best of luck with your project!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_task_instruction = (\"Your working directory should be\"\n",
    "\"/home/jovyan/shares/SR004.nfs2/rahmatullaev/rand_exps/Terminator/models_projects\"\n",
    "\"Never change anything outside of this directory. Check your working directory before executing any command.\"\n",
    "\"Inside it, create a new directory for each task you get (name it as the task name).\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_tasks = [\n",
    "    \"Task: 'test_file'. Create a new directory called 'test' inside project.\",\n",
    "    \"Task: 'hello_world'. Create a new file inside project called 'test.txt' and write 'Hello, world!' to it.\",\n",
    "    \"Task: 'list_files'. List all projects in your working directory.\",\n",
    "    \"Task: 'envs'. Write list of conda environments into 'envs.txt' file.\",\n",
    "    \"Task: 'gpu_info'. Write gpu info using nvidia-smi into 'gpu_info.txt' file.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add logging to terminal emulator \n",
    "# TODO: add structured output to model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07321e81db414b4cb63c85930d0edaf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from run_command import Terminator\n",
    "\n",
    "terminator = Terminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TASK:\n",
      " Your working directory should be/home/jovyan/shares/SR004.nfs2/rahmatullaev/rand_exps/Terminator/models_projectsNever change anything outside of this directory. Inside it, create a new directory for each task you get (name it as the task name).\n",
      "Task: 'hello_world'. Create a new file inside project called 'test.txt' and write 'Hello, world!' to it. \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LLM ANSWER:\n",
      " reasoning: I need to create a new directory named 'hello_world' inside the current working directory. Then, I will create a new file named 'test.txt' inside this directory and write 'Hello, world!' to it.\n",
      "command:mkdir hello_world && cd hello_world && echo \"Hello, world!\" > test.txt\n",
      "\n",
      "MODEL'S COMMAND: mkdir hello_world && cd hello_world && echo \"Hello, world!\" > test.txt\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 9] Bad file descriptor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[0;32m~/shares/SR004.nfs2/rahmatullaev/rand_exps/Terminator/run_command.py:219\u001b[0m, in \u001b[0;36mTerminator.run_terminal_task\u001b[0;34m(self, task_description, interactive)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 219\u001b[0m     terminal_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mterminal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTERMINAL OUTPUT:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/shares/SR004.nfs2/rahmatullaev/rand_exps/Terminator/run_command.py:43\u001b[0m, in \u001b[0;36mTerminalEmulator.send_command\u001b[0;34m(self, command, timeout)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;03mSend a command to the terminal and return the output.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;03m:raises TimeoutError: If waiting for the prompt times out.\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msendline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.mlspace/envs/rah_11_cu12.4_torch/lib/python3.12/site-packages/pexpect/pty_spawn.py:578\u001b[0m, in \u001b[0;36mspawn.sendline\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m    577\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coerce_send_string(s)\n\u001b[0;32m--> 578\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinesep\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.mlspace/envs/rah_11_cu12.4_torch/lib/python3.12/site-packages/pexpect/pty_spawn.py:569\u001b[0m, in \u001b[0;36mspawn.send\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m    568\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encoder\u001b[38;5;241m.\u001b[39mencode(s, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 569\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchild_fd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 9] Bad file descriptor",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m task_description \u001b[38;5;241m=\u001b[39m general_task_instruction \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m list_of_tasks[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m \u001b[43mterminator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_terminal_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask_description\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_description\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minteractive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/shares/SR004.nfs2/rahmatullaev/rand_exps/Terminator/run_command.py:235\u001b[0m, in \u001b[0;36mTerminator.run_terminal_task\u001b[0;34m(self, task_description, interactive)\u001b[0m\n\u001b[1;32m    230\u001b[0m         messages\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m    231\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    232\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTask reminder: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask_description\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTerminal output:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mterminal_output\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m         })\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m--> 235\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mterminal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSession ended.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/shares/SR004.nfs2/rahmatullaev/rand_exps/Terminator/run_command.py:67\u001b[0m, in \u001b[0;36mTerminalEmulator.close\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclose\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     64\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    Close the terminal session cleanly.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msendline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchild\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.mlspace/envs/rah_11_cu12.4_torch/lib/python3.12/site-packages/pexpect/pty_spawn.py:578\u001b[0m, in \u001b[0;36mspawn.sendline\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''Wraps send(), sending string ``s`` to child process, with\u001b[39;00m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;124;03m``os.linesep`` automatically appended. Returns number of bytes\u001b[39;00m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;124;03mwritten.  Only a limited number of bytes may be sent for each\u001b[39;00m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;124;03mline in the default terminal mode, see docstring of :meth:`send`.\u001b[39;00m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    577\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coerce_send_string(s)\n\u001b[0;32m--> 578\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinesep\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.mlspace/envs/rah_11_cu12.4_torch/lib/python3.12/site-packages/pexpect/pty_spawn.py:569\u001b[0m, in \u001b[0;36mspawn.send\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log(s, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msend\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    568\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encoder\u001b[38;5;241m.\u001b[39mencode(s, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 569\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchild_fd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 9] Bad file descriptor"
     ]
    }
   ],
   "source": [
    "task_description = general_task_instruction + \"\\n\" + list_of_tasks[1]\n",
    "\n",
    "terminator.run_terminal_task(task_description=task_description, interactive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.llms import HuggingFacePipeline\n",
    "# import torch\n",
    "# from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# class Joke(BaseModel):\n",
    "#     setup: str = Field(description=\"The setup of the joke\")\n",
    "#     punchline: str = Field(description=\"The punchline to the joke\")\n",
    "\n",
    "\n",
    "# # Use Hugging Face Hub API\n",
    "# pipeline = HuggingFacePipeline.from_model_id(\n",
    "#     model_id=\"Qwen/Qwen2.5-Coder-7B-Instruct\",\n",
    "#     task=\"text-generation\",\n",
    "#     pipeline_kwargs={\"max_new_tokens\": 10},\n",
    "#     device=0\n",
    "# )\n",
    "\n",
    "# pipeline.with_structured_output(Joke)\n",
    "# response = pipeline.invoke(\"User: What is your name? Assistant:\")\n",
    "# print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rah_11_cu12.4_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
